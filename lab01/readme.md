# Лаба 1. Расчет рейтингов фильмов – Scala

## Задача

По имеющимся данным о рейтингах фильмов (MovieLens: 100 000 рейтингов) посчитать агрегированную статистику по ним.

Цель в том, чтобы познакомится с методами Scala для обработки коллекций данных.

Нужно написать код на Scala (не на Spark), преобразующий входные данные из файлов в файл результата.

Вы загрузите входные данные из файлов в коллекцию в памяти (как это делает Spark, только у него коллекции распределенные по процессам и по хостам) и обработаете эти данные методами, похожими на методы обработки Spark'а.

Про проверку читайте пункт [Проверка](#Проверка) (ниже).

Про оформление читайте пункт [Оформление](#Оформление) (ниже).

Для того чтобы понять как разрабатывать и отлаживать код, ознакомьтесь с [Полезными советами](../FAQ.md), пункт Отладка.

В случае проблем смотрите [Подсказки](#Подсказки) или [Полезные советы](../FAQ.md#Решение-проблем), пункт Решение проблем.

## Описание данных

Имеются следующие входные данные:

* Таблица (в файле u.data) `users x movies` с пользовательскими оценками фильмов. Таблица загружена на кластер в HDFS в папку `/labs/laba01/ml-100k`.

Описание формата файлов, колонок есть в файле ml-100k/README.

* `id фильма` для расчета индивидуальных характеристик — в Личном кабинете на странице [Лабы 1](https://lk-spark-de.newprolab.com/lab/sb1laba01).

## Результат

Выходной формат файла — json. Пример решения:

```json
{
   "hist_film": [  
      134,
      123,
      782,
      356,
      148
   ],
   "hist_all": [  
      134,
      123,
      782,
      356,
      148
   ]
}
```

Другой пример:
```json
{"hist_film":[11,22,33,44,55],"hist_all":[134,123,782,356,148]}
```

В коде это карта (map) последовательностей (list/array/seq/...).

В поле `“hist_film”` нужно указать для заданного `id` фильма _количество_ поставленных оценок, отсортировав по оценкам по возрастанию: `"1", "2", "3", "4", "5"`. То есть, сколько было единичек, двоек, троек и т.д.

В поле `“hist_all”` нужно указать то же самое, только для всех фильмов общее количество поставленных оценок в том же порядке: `"1", "2", "3", "4", "5"`.

Не забудьте, что необходимо оформить и выложить после дедлайна свое решение (см. п. [Оформление](#Оформление)).

## Проверка

Файл результата необходимо положить в свою домашнюю директорию на ноде кластера под названием: `lab01.json`. Это можно сделать вручную. Можно через Юпитер.

Про проверку чекером смотрите [Полезные советы](../FAQ.md#Чекер), пункт Чекер.

В случае проблем смотрите [Полезные советы](../FAQ.md#Решение-проблем), пункт Решение проблем.

## Оформление

1. Оформляем свое решение в виде Scala (не Spark) проекта - _строго обязательно по инструкции по созданию [Scala проекта](../idea.md#Создание-Scala-проекта)_.
2. _Строго после (!) [дедлайна чекера](../README.md#Лабораторные)_ отправить проект в GitHub репозиторий на проверку: _строго обязательно по инструкции по созданию [Pull request'а](../git.md)_.

## Подсказки

В случае проблем смотрите [Полезные советы](../FAQ.md#Решение-проблем), пункт Решение проблем.

### Как скачать файлы

Команда для скачивания на ноду:
`hdfs dfs -get /labs/laba01/ml-100k ml-100k`

Либо в Jupiter notebook:
```
import sys.process._
"""hdfs dfs -get /labs/laba01/ml-100k ml-100k""".!!
```

При этом файлы окажутся в папке ml-100k на ноде.

Для проверки на компьютере скопируйте файлы на компьютер - [описано здесь](../ssh.md) в пункте Копирование файлов (или можно скопировать через Юпитер).

### Как прочитать данные из файла в коллекцию

:warning: Внимание! Не делайте так в реальных приложениях, так как вы не управляете размером файла, а он полностью читается в память. \
Здесь это исключительно для целей обучения т.к. есть гарантия, что файл небольшой.

Обрабатывать файлы в общем случае нужно построчно в цикле.

```
import scala.io.BufferedSource
import scala.io.Source.fromFile

//...
//внутри класса/объекта:

    //данные должны находиться по указанному пути:
    val source: BufferedSource = fromFile("путь_к_папке/u.data")
    
    //превращаем в коллекцию для демонстрации того что методы коллекций те же что и у RDD
    //т.к. RDD это по сути большая распределенная коллекция
    val lines: Seq[Array[String]] = source.getLines.toList //получаем List строк, в которых значения разделены табуляциями
      // и сразу нарезаем строки коллекции по табуляциям и превращаем в массивы значений
      .map(string => string.split("\t")) //Seq(Array(196, 242, 3, 881250949), Array(186, 302, 3, 891717742), ...)
    
    //закрываем BufferedSource, т.к. он нам уже не нужен а его ресурсы нужно освобождать
    source.close()
```

Добавьте в файл .gitignore в проекте папку с данными, если она находится в папке проекта.

### Методы обработки данных

Пересмотрите лекцию по Scala и обратите внимание на методы обработки данных в коллекциях.

.map \
.filter \
.groupBy \
.sortBy

Учтите, что каждый метод возвращает коллекцию и иногда коллекцию нужно преобразовывать в другую, т.к. у коллекций разный набор методов.

Подсказка: всегда обращайте внимание, какую коллекцию вы получили после преобразования, можно также посмотреть как выглядят в ней данные для наглядности (можно использовать println).

Чтобы код был читаемым, для работы с кортежами (tuple) в Scala можно использовать частично определенные функции, например:
```
.map { case (rating, array) => ...какой-то код... }
```

### Работа с JSON и добавление зависимостей

Работа с JSON на примере библиотеки json4s:
[Producing JSON](https://github.com/json4s/json4s#producing-json)

Добавить зависимость (внешнюю библиотеку), пример: 

В Jupyter:

```%AddDeps org.json4s json4s-jackson_2.11 3.2.11```

В проекте в build.sbt:

```libraryDependencies += "org.json4s" %% "json4s-jackson" % "3.2.11"```

Версии библиотек можно найти на [mvnrepository.com](https://mvnrepository.com/).

<!--
Как сформировать JSON в виде строки:
```
import org.json4s.JsonDSL._
import org.json4s.jackson.JsonMethods._

//...
//внутри класса/объекта:

    //с помощью библиотеки формируем JSON в виде строки
    val json: String = compact(render(ratings))
```
-->

### Сохранение в файл

Как сохранить строку в файл (для этого используем классы Java):
```
import java.io._

//...
//внутри класса/объекта:

    //создаем файл
    val file: File = new File("lab01.json")
    //создаем writer для записи файла
    val writer: BufferedWriter = new BufferedWriter(new FileWriter(file))
    //пишем строку в файл
    writer.write(json)
    //освобождаем ресурсы writer
    writer.close()
```

### Чекер

Пример правильного ответа чекера:
```
01_file lab01.json exists in your dir: True
02_file has all required fields: True
03_ratings histogram for all films is correct: True
04_ratings histogram for selected film is correct: True
05_lab is correct: True
status: last check failed
```

### Не забудьте

Не забудьте, что необходимо оформить и выложить после дедлайна свое решение (см. п. [Оформление](#Оформление)).

В случае проблем смотрите, пункт Решение проблем.